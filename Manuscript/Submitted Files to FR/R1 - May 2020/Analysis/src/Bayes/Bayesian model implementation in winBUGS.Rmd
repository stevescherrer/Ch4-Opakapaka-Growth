---
title: "R Notebook"
output: html_notebook
---
# Introduction
This is a notebook for estimating VonBertalanffy growth function parameters using bayesian methods for Pristipomoides filamentosus based on historic mark recapture tagging data using WinBUGS and the R2WinBUGS package.

## Workspace Setup
First we'll need to setup our workspace. This includes setting up our workspace directory, loading all libraries, and handing R the local path to BUGS 

```{r}
#### Establishing Directory Heirarchy ####
setwd('../..')
proj_dir = getwd()

if(!"Okamoto_Mark_Recapture" %in% strsplit(proj_dir, '/')[[1]]){
  proj_dir = file.path(getwd(), "Okamoto_Mark_Recapture")
}
data_dir = file.path(proj_dir, "data")
src_dir = file.path(proj_dir, "src")
results_dir = file.path(proj_dir, "results")

#### Loading Priniciple Dependencies ####
# install.packages('R2OpenBUGS')
library('R2WinBUGS')

### Path to BUGS ###
path2Bugs = "C:/Users/Weng Lab/Downloads/winbugs143_unrestricted/winbugs14_full_patched/WinBUGS14"
```


## Data
#### Cleaning Raw Data
Thanks to the folks at DAR, we've obtained a previously unpublished data set from the opakapaka tagging program. This data is from a mark recapture experiment where marking took place between 1989 and 1993. We load it in as a dataframe and take a look here:
```{r}
mark_recapture_data = read.csv(file.path(data_dir, 'HO Mstr, temp (version 1).csv'), stringsAsFactors =  FALSE)
print(colnames(mark_recapture_data))
head(mark_recapture_data)
```

Now We'll clean up our data  so each column is clearly labeled. We'll also remove  Along the way, we'll also get some basic info about our data (number of entries, number of recapture events, etc...)
```{r}
### Renaming data columns
colnames(mark_recapture_data) = c('tag_date', 'location', 'station', 'depth_f', 'species', 'previously_tagged', 'tag_id','fork_length_in', 'remarks', 'recapture_1_date', 'recapture_1_location', 'recapture_1_station', 'recapture_1_depth_f', 'recapture_1_fork_length_in', 'weight_1_lbs', 'days_1_free', 'growth_1_in', 'distance_1_miles','retagged_1',
                                  'recapture_2_date', 'recapture_2_location', 'recapture_2_station', 'recapture_2_depth_f', 'recapture_2_fork_length_in', 'weight_2_lbs', 'days_2_free', 'growth_2_in', 'distance_2_miles', 'retagged_2',
                                  'recapture_3_date', 'recapture_3_location', 'recapture_3_station', 'recapture_3_depth_f', 'recapture_3_fork_length_in', 'weight_3_lbs', 'days_3_free', 'growth_3_in', 'distance_3_miles', 'retagged_3',
                                  'recapture_4_date', 'recapture_4_location', 'recapture_4_station', 'recapture_4_depth_f', 'recapture_4_fork_length_in', 'weight_4_lbs', 'days_4_free', 'growth_4_in', 'distance_4_miles', 'x_retagged')


## How many total fish do we have in the data set?
n_tagged_fish = dim(mark_recapture_data)[1] # 4245!

### Subsetting out only Opakapaka with tag IDs - That is, fish that were marked
mark_recapture_data = mark_recapture_data[mark_recapture_data$species == '1' & mark_recapture_data$tag_id != '', ]
dim(mark_recapture_data)[1] # This gets you to the previously published 4179 tagged paka number from Kobayashi, Okamoto, & Oishi . for some reason doesn't exclude fish marked 'died'
n_tagged_paka = dim(mark_recapture_data)[1]

#### Adusting Data Classes
### Formatting Dates (Converting Characters to POSIXct)
mark_recapture_data$tag_date = as.POSIXct(mark_recapture_data$tag_date, format = "%Y-%m-%d")
mark_recapture_data$recapture_1_date = as.POSIXct(mark_recapture_data$recapture_1_date, format = "%Y-%m-%d")
mark_recapture_data$recapture_2_date = as.POSIXct(mark_recapture_data$recapture_2_date, format = "%Y-%m-%d")
mark_recapture_data$recapture_3_date = as.POSIXct(mark_recapture_data$recapture_3_date, format = "%Y-%m-%d")
mark_recapture_data$recapture_4_date = as.POSIXct(mark_recapture_data$recapture_4_date, format = "%Y-%m-%d")

### Formatting fork lengths
## We need to convert our forklength measurements from inches to cm and make sure everything is a numeric value.
## Note: There are a couple fork lengths that have ?, *, or have no lengths recorded. 
## I have no idea what these are but they're qualifiers and so I'm going to let them go to NA and get dropped from analysis
in_to_cm = 2.54
mark_recapture_data$fork_length_cm = as.numeric(mark_recapture_data$fork_length_in) * in_to_cm
mark_recapture_data$recapture_1_fork_length_cm = as.numeric(mark_recapture_data$recapture_1_fork_length_in) * in_to_cm
mark_recapture_data$recapture_2_fork_length_cm = as.numeric(mark_recapture_data$recapture_2_fork_length_in) * in_to_cm
mark_recapture_data$recapture_3_fork_length_cm = as.numeric(mark_recapture_data$recapture_3_fork_length_in) * in_to_cm
mark_recapture_data$recapture_4_fork_length_cm = as.numeric(mark_recapture_data$recapture_4_fork_length_in) * in_to_cm
```
Our data consists of `r n_tagged_fish` tagged fish. Of these, `r n_tagged_paka` are the species we're interested in.


We don't really care about fish that weren't recaptured so we'll exclude them at this stage
```{r}
### Removing fish that were not recaptured
mark_recapture_data = mark_recapture_data[!is.na(mark_recapture_data$recapture_1_fork_length_cm), ]
### This leaves us with 
dim(mark_recapture_data)[1] # individuals
```
Leaving us with `r dim(mark_recapture_data)[1]` opakapaka recaptured one or more times

#### Formatting data for BUGS model
In the following chunk, we'll create the data structures used by our BUGS model. 
Our model requires our data as a list containing the following objects
n: A vector corrosponding to each tag ID where values are numeric integers representing the number of times that individual was recaptured
L: a matrix of recorded fork lengths (cm) where rows indicate individual fish and columns are each recapture event. Each value of the matrix is a numeric corrosponding to the reported fork length. For fish with less than 4 recaptures, missing values are NA
dt: a matrix consisting of numeric values corrosponding the elapsed time (years) between the initial marking event and each recapture. For fish with less than 4 recaptures, missing values are NA.

We'll start by preallocating memory for our data objects
```{r}
## We know the maximum number of times a single fish was recaptured from the structure of our dataset
max_recaptures = 4
## Preallocating data objects in memory
n = rep(1, length(mark_recapture_data$tag_id))
L = matrix(nrow = length(mark_recapture_data$tag_id), ncol = (max_recaptures + 1), data = NA) # Note that matrix L gets an extra column corrosponding to initial fork length at tagging
dt = matrix(nrow = length(mark_recapture_data$tag_id), ncol = max_recaptures, data = NA) # Note that because dt is the difference in time, therefore it is one column less than L
```

And then we loop through each fish to fill in the data objects we've just created. Well also establish a minimum time at large for our fish
```{r}
min_time_at_lib = 0 # in days

for(i in 1:length(mark_recapture_data$tag_id)){
  ## For each individual, we start at the intial length at tagging and work our way up through recaptures
  L[i,1] = as.numeric(mark_recapture_data$fork_length_cm[i])
  ## Recapture 1
  if(!is.na(mark_recapture_data$recapture_1_fork_length_cm[i])){
    ## Calculate differece in time and if its greater than 60 days
    dt1 = difftime(mark_recapture_data$recapture_1_date[i], mark_recapture_data$tag_date[i], units = 'days') / 365
    if(all(!is.na(dt1) & dt1 > min_time_at_lib/365)){
    # Updating vector n
    n[i] = n[i] + 1
    # Getting recorded fork length
    L[i, 2] = as.numeric(mark_recapture_data$recapture_1_fork_length_cm[i])
    # Calculating time at liberty
    dt[i, 1] = as.numeric(dt1)
    }
  }
  
  ### Repeat the above for subsequent recaptures
  ## Recapture 2
  if(!is.na(mark_recapture_data$recapture_2_fork_length_cm[i])){
    dt2 = difftime(mark_recapture_data$recapture_2_date[i], mark_recapture_data$tag_date[i], units = 'days') / 36
    if(all(!is.na(dt2) & dt2 > min_time_at_lib/365)){
    n[i] = n[i] + 1
    L[i, 3] = as.numeric(mark_recapture_data$recapture_2_fork_length_cm[i])
    dt[i, 2] = as.numeric(dt2)
    }
  }
  
  ## Recapture 3
  if(!is.na(mark_recapture_data$recapture_3_fork_length_cm[i])){
    dt3 = difftime(mark_recapture_data$recapture_3_date[i], mark_recapture_data$tag_date[i], units = 'days') / 365
    if(all(!is.na(dt3) & dt3 > min_time_at_lib/365)){
    n[i] = n[i] + 1
    L[i, 4] = as.numeric(mark_recapture_data$recapture_3_fork_length_cm[i])
    dt[i, 3] = as.numeric(dt3)
    }
  }
  
  if(!is.na(mark_recapture_data$recapture_4_fork_length_cm[i])){
    dt4 = difftime(mark_recapture_data$recapture_4_date[i], mark_recapture_data$tag_date[i], units = 'days') / 365
    if(all(!is.na(dt4) & dt4 > min_time_at_lib/365)){
    n[i] = n[i] + 1
    L[i, 5] = as.numeric(mark_recapture_data$recapture_4_fork_length_cm[i])
    dt[i,4] = as.numeric(dt4)
    }
  }
}

rm_ind = which(is.na(L[ ,1]))
n = n[-rm_ind]; L = L[-rm_ind, ]; dt = dt[-rm_ind, ]

### L and dt matricies need to be adjusted for fish recaptured more than once but for whom one of their recaptures was excluded for being less than our 60 day threshold
## Set up vector indexing which fish to remove after our loop.We will remove fish that have no recaptures after 60 days a liberty.
valid_recaps = rep(TRUE, dim(dt)[1])

## Loop through each fish
for(i in 1:dim(dt)[1]){
    # If the first column of NAs does not come after the last column of data or if the whole row isn't NAs
    while(!all(is.na(dt[i, ])) && (!max(which(!is.na(dt[i, ]))) < min(which(is.na(dt[i, ]))))){
      # We shift all our data after the NA over by one and try again 
      L[i, (1 + min(which(is.na(dt[i, ])))):ncol(dt)] =  c(L[i, (1 + (min(which(is.na(dt[i, ]))))+ 1):ncol(dt)], NA)
      dt[i, min(which(is.na(dt[i, ]))):ncol(dt)] =  c(dt[i, (min(which(is.na(dt[i, ]))) + 1):ncol(dt)], NA)

    }
  if(all(is.na(dt[i, ]))){
    valid_recaps[i] = FALSE
  }
}

## Removing fish without valid recaptures
dt = dt[valid_recaps, ]
L = L[valid_recaps, ]

n = rep(0, length(dt[,1]))
for(i in 1:length(n)){
  n[i] = length(L[i, ]) - length(which(is.na(L[i, ])))
}

N = length(n)

data = list(n = n, L = L, dt = dt, N = N)

```

So now we've got a data set consisting of `r length(which(n >= 1))` recaptured fish with times at liberty exceeding 60 days.

`r length(which(n == 5))` individuals were recaptured 4 times, `r length(which(n == 4))` individuals were recaptured 3 times, `r length(which(n == 3))` individuals were recaptured 2 times, and `r length(which(n == 2))` individuals were captured only once


## Model Specification
In this section we define 4 models for fitting our growth curves that differ from eachother only slightly. 
Model 1 draws both Linf and k parameters from presumed distributions
Model 2 draws Linf from a presumed distribution while k is fixed
Model 3 draws k from a presumed distribution while Linf is fixed
Model 4 treats both k and Linf as fixed parameters
```{r}
### Model 1
sink(file = file.path(src_dir,'Bayes/model1upd.txt'), type = 'output')
writeLines('## Model 1
model{   			
  # Loop through individual fish
	for (i in 1:dim(dt)[1])	 {
	  # loop through each subsequent recapture
		for(j in ((1:n[i])+1)){
		  ## Calculate expected length for each recaptures
		L[i, j] ~ dnorm(L_Exp[i, j], tau)	
		L_Exp[i, j] <-  Linf[i] *(1.0 - exp(-k[i]*(A[i]+dt[i, j-1])))
		L.pred[i, j] ~ dnorm(L_Exp[i, j], tau)
		p.value[i, j] <- step(L.pred[i, j] - L[i, j])
		}
	  # Calculate estimated length at tagging
		L[i, 1] ~ dnorm(L_Exp[i, 1], tau)
		L_Exp[i, 1] <-   Linf[i] *(1.0 - exp(-k[i]*A[i]))	
		L.pred[i, 1] ~ dnorm(L_Exp[i, 1], tau)
		p.value[i, 1] <- step(L.pred[i, 1]- L[i, 1])
		Linf[i] ~ dnorm(Linf_mu,  Linf_tau)		
		k[i] ~ dnorm(k_mu, k_tau) I(0,1)
		A[i] ~ dgamma(shape, rate)
	}
	Linf_std <- sqrt(1/Linf_tau)
	k_std <- sqrt(1/k_tau)
	var <- 1/tau
	Linf_mu ~ dnorm(100, 0.0001)
	Linf_tau ~ dgamma(0.01, 0.0001)
	shape ~ dunif(0, 100)
	rate ~ dunif(0, 100)
	k_mu ~ dbeta(1, 1)
	k_tau ~ dgamma(0.01, 0.0001)
	tau ~ dgamma(0.01, 0.0001)
}')
sink()

### Model 2
sink(file = file.path(src_dir,'Bayes/model2upd.txt'), type = 'output')
writeLines('## Model 2
model{   			
  # Loop through individual fish
	for (i in 1:dim(dt)[1])	 {
	  # loop through each subsequent recapture
		for(j in (1:n[i])+1){
		  ## Calculate expected length for each recaptures
		L[i, j] ~ dnorm(L_Exp[i, j], tau)	
		L_Exp[i, j] <-  Linf[i] *(1.0 - exp(-k[i]*(A[i]+dt[i, j-1])))
		L.pred[i, j] ~ dnorm(L_Exp[i, j], tau)
		p.value[i, j] <- step(L.pred[i, j] - L[i, j])
		}
	  # Calculate estimated length at tagging
		L[i, 1] ~ dnorm(L_Exp[i, 1], tau)
		L_Exp[i, 1] <-   Linf[i] *(1.0 - exp(-k[i]*A[i]))	
		L.pred[i, 1] ~ dnorm(L_Exp[i, 1], tau)
		p.value[i, 1] <- step(L.pred[i, 1]- L[i, 1])
		Linf[i] ~ dnorm(Linf_mu,  Linf_tau)		
		k[i] ~ dnorm(k_mu, k_tau) I(0,1)
		A[i] ~ dgamma(shape, rate)
	}
  Linf_std <- sqrt(1/Linf_tau)
	k_std <- sqrt(1/k_tau)
	var <- 1/tau
	k ~ dnorm(k_mu, k_tau) I(0,1)
	Linf_mu ~ dnorm(100, 0.0001)
	Linf_tau ~ dgamma(0.01, 0.0001)
	shape ~ dunif(0, 100)
	rate ~ dunif(0, 100)
	k_mu ~ dbeta(1, 1)
	k_tau ~ dgamma(0.01, 0.0001)
	tau ~ dgamma(0.01, 0.0001)
}')
sink()

### Model 3
sink(file = file.path(src_dir,'Bayes/model3upd.txt'), type = 'output')
writeLines('## Model 3
model{   			
  # Loop through individual fish
	for (i in 1:dim(dt)[1])	 {
	  # loop through each subsequent recapture
		for(j in ((1:n[i])+1)){
		  ## Calculate expected length for each recaptures
		L[i, j] ~ dnorm(L_Exp[i, j], tau)	
		L_Exp[i, j] <-  Linf[i] *(1.0 - exp(-k[i]*(A[i]+dt[i, j-1])))
		L.pred[i, j] ~ dnorm(L_Exp[i, j], tau)
		p.value[i, j] <- step(L.pred[i, j] - L[i, j])
		}
	  # Calculate estimated length at tagging
		L[i, 1] ~ dnorm(L_Exp[i, 1], tau)
		L_Exp[i, 1] <-   Linf[i] *(1.0 - exp(-k[i]*A[i]))	
		L.pred[i, 1] ~ dnorm(L_Exp[i, 1], tau)
		p.value[i, 1] <- step(L.pred[i, 1]- L[i, 1])
		Linf[i] ~ dnorm(Linf_mu,  Linf_tau)		
		k[i] ~ dnorm(k_mu, k_tau) I(0,1)
		A[i] ~ dgamma(shape, rate)
	}
	Linf_std <- sqrt(1/Linf_tau)
	k_std <- sqrt(1/k_tau)
	var <- 1/tau
	Linf ~ dnorm(Linf_mu,  Linf_tau)
	Linf_mu ~ dnorm(100, 0.0001)
	Linf_tau ~ dgamma(0.01, 0.0001)
	shape ~ dunif(0, 100)
	rate ~ dunif(0, 100)
	k_mu ~ dbeta(1, 1)
	k_tau ~ dgamma(0.01, 0.0001)
	tau ~ dgamma(0.01, 0.0001)
}')
sink()

### Model 4
sink(file = file.path(src_dir,'Bayes/model4upd.txt'), type = 'output')
writeLines('## Model 4
model{   			
  # Loop through individual fish
	for (i in 1:dim(dt)[1])	 {
	  # loop through each subsequent recapture
		for(j in (1:n[i])+1){
		  ## Calculate expected length for each recaptures
		L[i, j] ~ dnorm(L_Exp[i, j], tau)	
		L_Exp[i, j] <-  Linf[i] *(1.0 - exp(-k[i]*(A[i]+dt[i, j-1])))
		L.pred[i, j] ~ dnorm(L_Exp[i, j], tau)
		p.value[i, j] <- step(L.pred[i, j] - L[i, j])
		}
	  # Calculate estimated length at tagging
		L[i, 1] ~ dnorm(L_Exp[i, 1], tau)
		L_Exp[i, 1] <-   Linf[i] *(1.0 - exp(-k[i]*A[i]))	
		L.pred[i, 1] ~ dnorm(L_Exp[i, 1], tau)
		p.value[i, 1] <- step(L.pred[i, 1]- L[i, 1])
		Linf[i] ~ dnorm(Linf_mu,  Linf_tau)		
		k[i] ~ dnorm(k_mu, k_tau) I(0,1)
		A[i] ~ dgamma(shape, rate)
	}
  Linf_std <- sqrt(1/Linf_tau)
	k_std <- sqrt(1/k_tau)
	var <- 1/tau
	k ~ dnorm(k_mu, k_tau) I(0,1)
	Linf ~ dnorm(Linf_mu,  Linf_tau)
	Linf_mu ~ dnorm(100, 0.0001)
	Linf_tau ~ dgamma(0.01, 0.0001)
	shape ~ dunif(0, 100)
	rate ~ dunif(0, 100)
	k_mu ~ dbeta(1, 1)
	k_tau ~ dgamma(0.01, 0.0001)
	tau ~ dgamma(0.01, 0.0001)
}')
sink()
```


```{r}
for(i in 1:length(n)){
  if(any(is.na(L[i, 1:n[i]]) | is.na(dt[i, n[i]-1]))){
    print(i)
  }
}

```

Before running our model, we'll want establish some initial paramter estimates to hand to each chain.
We'll run 3 chains, one with our parameter estimates, and two additional chains where parameter estimates have been increased/decreased by a factor of 2. Convergence of all chains will indicate goodness of fit.
```{r}
## Set initial parameters
# inits = function(){
#    # list(    
#     list(Linf_mu = 60, Linf_tau = 0.03, shape = 56, rate = 21, k_mu = 0.3, k_tau = 9121, tau = 0.12)#,
#   #  list(Linf_mu = 60*.5, Linf_tau = 0.03*.5, shape = 56*.5, rate = 21*.5, k_mu = 0.3*.5, k_tau = 9121*.5, tau = 0.12*.5),
#   #  list(Linf_mu = 60*2, Linf_tau = 0.03*2, shape = 56*2, rate = 21*2, k_mu = 0.3*2, k_tau = 9121*2, tau = 0.12*2)
#   #  )
# }


  inits1 = list(Linf_mu = 60, Linf_tau = 0, shape = 56, rate = 21, k_mu = 0.3, k_tau = 0, tau = 0)
  inits2 = list(Linf_mu = 60*2, Linf_tau = 0, shape = 56, rate = 21, k_mu = 0.3*2, k_tau = 0, tau = 0) 
  inits3 = list(Linf_mu = 60/2, Linf_tau = 0, shape = 56, rate = 21, k_mu = 0.3/2, k_tau = 0, tau = 0)


inits = list(inits1, inits2, inits3)
```
  

Finally it's time to run each model
```{r}
## Run Models
model_1 = bugs(data, inits, 
               model.file = file.path(src_dir,'Bayes/model1upd.txt'),
              # parameters = c('Linf_std', 'k_std', 'var', 'Linf_mu', 'Linf_tau', 'shape', 'rate', 'k_mu', 'k_tau', 'tau'), 
              parameters.to.save =  c('Linf_mu', 'Linf_std', 'k_mu', 'k_std', 'shape', 'rate', 'tau', 'Linf_tau', 'k_tau'),
              DIC = T, 
              n.chains = 3, n.iter = 500000, n.burnin = 10000, n.thin = 50, debug = F, 
               bugs.directory = "C:/Users/Weng Lab/Downloads/winbugs143_unrestricted/winbugs14_full_patched/WinBUGS14")

model_2 = beep()bugs(data, inits, 
               model.file = file.path(src_dir, 'Bayes/model2upd.txt'),
               parameters = c('Linf_std', 'k_std', 'var', 'k', 'Linf_mu', 'Linf_tau', 'shape', 'rate', 'k_mu', 'k_tau', 'tau'), 
               n.chains = 1, n.iter = 500000, n.burnin = 10000, n.thin = 50,
               bugs.directory = "C:/Users/Weng Lab/Downloads/winbugs143_unrestricted/winbugs14_full_patched/WinBUGS14",
               debug = T)

model_3 = bugs(data, inits, 
               model.file = file.path(src_dir, 'Bayes/model3upd.txt'),
               parameters = c('Linf_mu', 'Linf_std', 'Linf_tau', 'shape', 'k_mu', 'k_std', 'k_tau', 'rate', 'tau', 'var'), 
               n.chains = 1, n.iter = 500000, n.burnin = 10000, n.thin = 50,
               bugs.directory = "C:/Users/Weng Lab/Downloads/winbugs143_unrestricted/winbugs14_full_patched/WinBUGS14",
               debug = F)

model_4 = bugs(data, inits, 
               model.file = file.path(src_dir, 'Bayes/model4upd.txt'),
               parameters = c('Linf_mu', 'Linf_std', 'Linf_tau', 'shape', 'k_mu', 'k_std', 'k_tau', 'rate', 'tau', 'var'), 
               n.chains = 1, n.iter = 500000, n.burnin = 10000, n.thin = 50,
               bugs.directory = "C:/Users/Weng Lab/Downloads/winbugs143_unrestricted/winbugs14_full_patched/WinBUGS14",
               debug = F)
```